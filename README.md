<p align="center">
  <img src="https://img.icons8.com/fluency/96/shield.png" width="90" />
</p>

<h1 align="center">ğŸ›¡ï¸ Brand Guardian AI</h1>

<p align="center">
  <b>Fully Local Video Advertisement Compliance Audit Pipeline</b><br>
  Whisper â€¢ EasyOCR â€¢ FAISS â€¢ Mistral (Ollama) â€¢ FastAPI
</p>

<p align="center">
  <img src="https://img.shields.io/badge/LLM-Mistral-blue" />
  <img src="https://img.shields.io/badge/RAG-FAISS-green" />
  <img src="https://img.shields.io/badge/Backend-FastAPI-009688" />
  <img src="https://img.shields.io/badge/Runtime-Local-orange" />
  <img src="https://img.shields.io/badge/License-MIT-lightgrey" />
</p>

---

## ğŸ“Œ Overview

**Brand Guardian AI** is a fully local, end-to-end video advertisement compliance auditing system.

It automatically analyzes YouTube advertisements, extracts speech and on-screen text, retrieves relevant regulatory policies using Retrieval-Augmented Generation (RAG), and generates structured compliance verdicts using a transformer-based LLM.

> âœ… No Azure  
> âœ… No cloud APIs  
> âœ… Fully local execution  

When an ad fails compliance, the system provides:
- **Why it failed** â€” Specific violation reasons  
- **How to fix it** â€” Clear, actionable recommendations  

---

## ğŸ—ï¸ Architecture

User â†’ FastAPI â†’ YouTube URL

â†“
Download Video (yt-dlp)
â†“
Whisper â†’ Transcript EasyOCR â†’ On-screen Text
â†“
Combine â†’ Structured Text
â†“
Chunking (1000 chars, 200 overlap)
â†“
Embeddings (all-MiniLM-L6-v2)
â†“
FAISS Retrieval (top-3)
â†“
Ollama / Mistral â†’ Compliance Verdict (JSON)

---

## ğŸš€ Key Features

- ğŸ¥ YouTube ingestion via `yt-dlp`
- ğŸ™ Speech recognition using **Whisper (Transformer-based ASR)**
- ğŸ‘ OCR extraction using **EasyOCR**
- ğŸ“š Semantic policy retrieval via **FAISS (RAG)**
- ğŸ§  Compliance reasoning using **Mistral (Ollama)**
- âš¡ Parallel Whisper + OCR processing
- ğŸ”„ Async task tracking with progress polling
- ğŸ©º Health check endpoint
- ğŸ”’ Fully local deployment

---

## ğŸ“ Project Structure

Brand_Guardian/
â”œâ”€â”€ main.py # FastAPI entry point
â”œâ”€â”€ video_processor.py # Download + Whisper + EasyOCR
â”œâ”€â”€ rag_pipeline.py # PDF loading, chunking, FAISS index
â”œâ”€â”€ llm_engine.py # Ollama prompt + response parsing
â”œâ”€â”€ utils.py # Logging and helpers
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.bat
â”œâ”€â”€ start.bat
â”œâ”€â”€ QUICKSTART.md
â”œâ”€â”€ static/
â”‚ â””â”€â”€ index.html
â”œâ”€â”€ knowledge_base/
â”‚ â””â”€â”€ (Place compliance PDFs here)
â””â”€â”€ downloads/


---

## âš™ï¸ Prerequisites

| Dependency | Purpose |
|------------|----------|
| Python 3.10+ | Runtime |
| ffmpeg | Required for Whisper |
| Ollama | Local LLM runtime |
| Mistral model | `ollama pull mistral` |

---

## ğŸ› ï¸ Setup

### Windows (Quick Start)

```powershell
.\setup.bat
.\start.bat

# 1. Create virtual environment
python -m venv .venv
.venv\Scripts\activate        # Windows
# source .venv/bin/activate   # macOS / Linux

# 2. Install dependencies
pip install -r requirements.txt

# 3. Install ffmpeg
# Windows: winget install ffmpeg
# macOS:   brew install ffmpeg
# Linux:   sudo apt install ffmpeg

# 4. Start Ollama (separate terminal)
ollama serve
ollama pull mistral

# 5. Place compliance PDFs in knowledge_base/

# 6. Run server
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
